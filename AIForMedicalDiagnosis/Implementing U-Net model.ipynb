{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a network architecture called \"U-Net\". The name of this network architecture comes from it's U-like shape when shown in a diagram like this (image from [U-net entry on wikipedia](https://en.wikipedia.org/wiki/U-Net)): \n",
    "\n",
    "<img src=\"u-net.jpg\" width=\"600\"/>\n",
    "\n",
    "U-nets are commonly used for image segmentation. As you can see from the diagram, this architecture features a series of down-convolutions connected by max-pooling operations, followed by a series of up-convolutions connected by upsampling and concatenation operations. Each of the down-convolutions is also connected directly to the concatenation operations in the upsampling portion of the network. For more detail on the U-Net architecture, have a look at the original [U-Net paper by Ronneberger et al. 2015](https://arxiv.org/abs/1505.04597). \n",
    "\n",
    "We'll create a basic U-Net using Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, PReLU, Deconvolution3D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "# Set the image shape to have the channels in the first dimension\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth of U-Net**\n",
    "\n",
    "The \"depth\" of your U-Net is equal to the number of down-convolutions you will use. In the image above, the depth is 4 because there are 4 down-convolutions running down the left side including the very bottom of the U.\n",
    "\n",
    "For the examples next, we'll use a U-Net depth of 2, meaning we'll have 2 down-convolutions in your network. \n",
    "\n",
    "The shape of the input layer is `(num_channels, height, width, length)`, where `num_channels` you can think of like color channels in an image, `height`, `width` and `length` are just the size of the input.\n",
    "\n",
    "The values will be using will be:\n",
    "- num_channels: 4\n",
    "- height: 160\n",
    "- width: 160\n",
    "- length: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0428 16:52:19.885658 4442424768 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0428 16:52:19.912508 4442424768 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 4, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an input layer tensor of the shape \n",
    "input_layer = Input(shape=(4, 160, 160, 16))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tensor shape has a '?' as the very first dimension.  This will be the batch size. So the dimensions of the tensor are: (batch_size, num_channels, height, width, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contracting (downward) path**\n",
    "\n",
    "Here we'll be constructing the downward path in the network (the left size of the U-Net). The <mark>(height, width, length) </mark> of the input gets smaller as you move down this path, and the number of channels increases. \n",
    "\n",
    "**Depth 0**\n",
    "\n",
    "By \"depth 0\" here, we are referring to the depth of the first down-convolution in the U-net. \n",
    "\n",
    "The number of filters is specified for each depth and for each layer within the depth. \n",
    "\n",
    "The formula to use for calculating the number of filters is:\n",
    "$$\\mathcal filters_{i} = 32 \\times (2^{i}) $$\n",
    "\n",
    "where $\\mathcal i$ is the current depth. \n",
    "\n",
    "So at the depth $\\mathcal i = 0$:\n",
    "$$ \\mathcal filters_{0} = 32 \\times (2^{0}) = 32 $$\n",
    "\n",
    "**Layer 0**\n",
    "\n",
    "There are two convolutional layers for each depth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0428 17:03:21.459342 4442424768 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0428 17:03:21.476487 4442424768 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0428 17:03:21.477242 4442424768 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3d_1/add:0' shape=(?, 32, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a Conv3D tensor with 32 filters\n",
    "down_depth_0_layer_0 = Conv3D(filters=32,\n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                             )(input_layer)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the 32 filters, the result you get above is a tensor with 32 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_1/Relu:0' shape=(?, 32, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a relu activation to layer 0 of depth 0\n",
    "down_depth_0_layer_0 = Activation('relu')(down_depth_0_layer_0)\n",
    "down_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth 0, Layer 1**\n",
    "\n",
    "For layer 1 of depth 0, the formula you'll use for number of filters is:\n",
    "$$ \\mathcal_{i} = 32 \\times (2^{i}) \\times 2\n",
    "\n",
    "Where $\\mathcal i$ is the current depth. \n",
    "\n",
    "* Notice that the '$\\times 2$' at the end of this expression isn't there for layer 0. \n",
    "\n",
    "So at depth $\\mathcal i = 0$ for layer 1:\n",
    "$$\\mathcal filters_{0} = 32 \\times (2^{0}) \\times 2 = 64$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Conv3D layer with 64 filters to your network and add relu activation. \n",
    "down_depth_0_layer_1 = Conv3D(filters=64, \n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                             )(down_depth_0_layer_0)\n",
    "down_depth_0_layer_1 = Activation('relu')(down_depth_0_layer_1)\n",
    "down_depth_0_layer_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Pooling**\n",
    "\n",
    "Within the U-Net architecture, there is a max pooling operation after each of the down-convolutions (not including the last down-convolution at the bottom of the U). In general, this means you'll add max pooling after each down-convolution up to (but not including) the <mark>depth -1</mark> down convolution (since you started counting at 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'max_pooling3d_1/transpose_1:0' shape=(?, 64, 80, 80, 8) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a max pooling layer\n",
    "down_depth_0_layer_pool = MaxPooling3D(pool_size=(2,2,2))(down_depth_0_layer_1)\n",
    "down_depth_0_layer_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth 1, Layer 0**\n",
    "\n",
    "At depth 1, layer 0, the formula for calculating the number of filters is:\n",
    "$$\\mathcal filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $\\mathcal i$ is the current depth.\n",
    "\n",
    "So at depth $\\mathcal i = 1$:\n",
    "$$\\mathcal filters_{i} = 32 \\times (2^{1}) = 64$$\n",
    "\n",
    "The next cell adds a Conv3D layer to the network with relu activation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_3/Relu:0' shape=(?, 64, 80, 80, 8) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Conv3D layer to your network with relu activation\n",
    "down_depth_1_layer_0 = Conv3D(filters=64, \n",
    "                              kernel_size=(3,3,3),\n",
    "                              padding='same',\n",
    "                              strides=(1,1,1)\n",
    "                             )(down_depth_0_layer_pool)\n",
    "down_depth_1_layer_0 = Activation('relu')(down_depth_1_layer_0)\n",
    "down_depth_1_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth 1, Layer 1**\n",
    "\n",
    "For layer 1 of depth 1 the formula you'll use for number of filters is:\n",
    "\n",
    "$$\\mathcal filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $\\mathcal i$ is the current depth.\n",
    "\n",
    "* Notice that the $'\\times 2'$ at the end of this expression isn't there for layer 0. \n",
    "\n",
    "So at depth $\\mathcal = 1$:\n",
    "\n",
    "$$ \\mathcal filters_{0} = 32 \\times (2^{1}) \\times 2 = 128 $$\n",
    "\n",
    "The next cell adds another Conv3D with 128 filters to the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_5/Relu:0' shape=(?, 128, 80, 80, 8) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add another Conv3D with 128 filters to your network. \n",
    "down_depth_1_layer_1 = Conv3D(filters=128, \n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(down_depth_1_layer_0)\n",
    "down_depth_1_layer_1 = Activation('relu')(down_depth_1_layer_1)\n",
    "down_depth_1_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No max pooling at depth 1(the bottom of the U)**\n",
    "\n",
    "At the \"bottom\" of the U-net, there is no need to apply max pooling after the convolutions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding (upward) Path\n",
    "\n",
    "Now we'll work on the expanding path of the U-Net, (going up on the right side, when viewing the diagram). The image's (height, width, length) all get larger in the expanding path.\n",
    "\n",
    "**Depth 0, Up sampling layer 0**\n",
    "\n",
    "We'll be using a pool size of (2,2,2) for upsampling. \n",
    "\n",
    "- This is the default value for [tf.keras.layers.UpSampling3D]\n",
    "(https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling3D)\n",
    "- As input to the upsampling at depth 1, you'll use the last layer of the downsampling. In this case, it's a depth 1 layer 1. \n",
    "\n",
    "Next cell adds an upsampling operation to your network. Note that we are not adding any activation to this upsampling layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'up_sampling3d_1/concat_2:0' shape=(?, 128, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an upsampling operation to your network\n",
    "up_depth_0_layer_0 = UpSampling3D(size=(2,2,2))(down_depth_1_layer_1)\n",
    "up_depth_0_layer_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate upsampled depth 0 with downsampled depth 0**\n",
    "\n",
    "Now you'll apply a concatenation operation using the layers that are both at the same depth of 0. \n",
    "\n",
    "* up_depth_0_layer_0: shape is (?, 128, 160, 160, 16)\n",
    "* depth_0_layer_1: shape is (?, 64, 160, 160, 16)\n",
    "* Double check that both these layers have the same height, width and length. \n",
    "* The (height, width, length) is (160, 160, 16) for both. \n",
    "\n",
    "The next cell checks that the layers we wish to concatenate have the same height, width and length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"up_sampling3d_1/concat_2:0\", shape=(?, 128, 160, 160, 16), dtype=float32)\n",
      "\n",
      "Tensor(\"activation_2/Relu:0\", shape=(?, 64, 160, 160, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of layers to concatenate\n",
    "print(up_depth_0_layer_0)\n",
    "print()\n",
    "print(down_depth_0_layer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will add a concatenation operation to your network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 192, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a concate along axis 1\n",
    "up_depth_1_concat = concatenate([up_depth_0_layer_0,\n",
    "                                 down_depth_0_layer_1],\n",
    "                                 axis=1)\n",
    "up_depth_1_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the upsampling layer had 128 channels, and the down-convolution layer had 64 channels so that when concatenated, the results has 128 + 64 = 192 channels. \n",
    "\n",
    "**Up-convolution layer 1**\n",
    "\n",
    "The number of filters for this layer will be set to the number of channels is the down-convolution's layer 1 at the same depth of 0 (down_depth_0_layer_1). \n",
    "\n",
    "The next cell displays the shape of the down-convolution depth 0 layer 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth_0_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the number of channels for <mark>depth_0_layer_1</mark> is 64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of filters: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of filters: {down_depth_0_layer_1._keras_shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_6/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_1 = Conv3D(filters=64,\n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_concat)\n",
    "up_depth_1_layer_1 = Activation('relu')(up_depth_1_layer_1)\n",
    "up_depth_1_layer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Up-convolution depth 0, layer 2**\n",
    "\n",
    "At layer 2 of depth 0 in the up-convolution the next step will be to add another up-convolution. The number of filters you'll want to use for this next up-convolution will need to be equal to the number of filters in the down-convolution depth 0 layer 1. \n",
    "\n",
    "The next cell reminds of the number of filters in down-convolution depth 0  layer 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_2/Relu:0\", shape=(?, 64, 160, 160, 16), dtype=float32)\n",
      "number of filters: 64\n"
     ]
    }
   ],
   "source": [
    "print(down_depth_0_layer_1)\n",
    "print(f'number of filters: {down_depth_0_layer_1._keras_shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the number of channels/filters in <mark>down_depth_0_layer_1</mark> is 64. \n",
    "\n",
    "The next cell to add a Conv3D up-convolution with 64 filters to your network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_7/Relu:0' shape=(?, 64, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a Conv3D up-convolution with 64 filters to your network\n",
    "up_depth_1_layer_2 = Conv3D(filters=64,\n",
    "                            kernel_size=(3,3,3),\n",
    "                            padding='same',\n",
    "                            strides=(1,1,1)\n",
    "                           )(up_depth_1_layer_1)\n",
    "up_depth_1_layer_2 = Activation('relu')(up_depth_1_layer_2)\n",
    "up_depth_1_layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Convolution**\n",
    "\n",
    "For the final convolution, you'll set the number of filters to be equal to the number of classes in your input data. \n",
    "\n",
    "Here, we have 3 classes, namely:\n",
    "\n",
    "* 1:edema\n",
    "* 2:non-enhancing tumor\n",
    "* 3:enhancing tumor\n",
    "\n",
    "The next cell adds a final Conv3D with 3 filters to your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv3d_10/add:0' shape=(?, 3, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a final Conv3D with 3 filters to your network. \n",
    "final_conv = Conv3D(filters=3, #3 categories\n",
    "                    kernel_size=(1,1,1),\n",
    "                    padding='valid',\n",
    "                    strides=(1,1,1)\n",
    "                   )(up_depth_1_layer_2)\n",
    "final_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation for final convolution**\n",
    "\n",
    "The next cell adds a sigmoid activation function to your final convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_8/Sigmoid:0' shape=(?, 3, 160, 160, 16) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a sigmoid activation to your final convolution. \n",
    "final_activation = Activation('sigmoid')(final_conv)\n",
    "final_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 13:26:25.004676 4442424768 deprecation_wrapper.py:119] From /anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define and compile your model\n",
    "model = Model(inputs=input_layer, outputs=final_activation)\n",
    "model.compile(optimizer=Adam(lr=0.00001),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['categorical_accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4, 160, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 32, 160, 160, 3488        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 160, 160, 0           conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 64, 160, 160, 55360       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 160, 160, 0           conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 80, 80, 8 0           conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 128, 80, 80,  221312      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 80, 80,  0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_1 (UpSampling3D)  (None, 128, 160, 160 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_1[0][0]            \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 64, 160, 160, 331840      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 160, 160, 0           conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 64, 160, 160, 110656      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 160, 160, 0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 3, 160, 160,  195         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 3, 160, 160,  0           conv3d_10[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 833,507\n",
      "Trainable params: 833,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print out a summary of the model we have created\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double check your model**\n",
    "\n",
    "To double check that we've created the correct model, use a function that we've provided to create the same model, and check that the layers and layer dimensions match!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import predefined utilities\n",
    "import util_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using a predefined function\n",
    "model_2 = util_3.unet_model_3d(depth=2,\n",
    "                             loss_function='categorical_crossentropy',\n",
    "                             metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 4, 160, 160,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 32, 160, 160, 3488        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 160, 160, 0           conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 64, 160, 160, 55360       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 160, 160, 0           conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 64, 80, 80, 8 110656      max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 80, 80, 8 0           conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 128, 80, 80,  221312      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 80, 80,  0           conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling3d_2 (UpSampling3D)  (None, 128, 160, 160 0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_2[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 64, 160, 160, 331840      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 160, 160, 0           conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_16 (Conv3D)              (None, 64, 160, 160, 110656      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 160, 160, 0           conv3d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_17 (Conv3D)              (None, 3, 160, 160,  195         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 3, 160, 160,  0           conv3d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 833,507\n",
      "Trainable params: 833,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print out a summary of the model created by the predefined function \n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
